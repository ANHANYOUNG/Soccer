{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3db2d0b-9fb7-4e6a-a2ae-040006a4779d",
   "metadata": {
    "id": "d3db2d0b-9fb7-4e6a-a2ae-040006a4779d"
   },
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e82bf68-4f23-4a14-b69c-b34c351ffd06",
   "metadata": {
    "executionInfo": {
     "elapsed": 3369,
     "status": "ok",
     "timestamp": 1766391961315,
     "user": {
      "displayName": "안한영",
      "userId": "07109810963183759514"
     },
     "user_tz": -540
    },
    "id": "5e82bf68-4f23-4a14-b69c-b34c351ffd06"
   },
   "outputs": [],
   "source": [
    "# file/path uilities\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# for data manipulation/math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# encoding (type_name to number) / split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# deep learning framework\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence # padding to handle variable length sequences\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73493fd5-d0b6-4bb5-8ec2-148d5a920a81",
   "metadata": {
    "id": "73493fd5-d0b6-4bb5-8ec2-148d5a920a81"
   },
   "source": [
    "## 2. 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2481df09-f3ac-4bf6-b307-cc24faf5e65c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1766391962647,
     "user": {
      "displayName": "안한영",
      "userId": "07109810963183759514"
     },
     "user_tz": -540
    },
    "id": "2481df09-f3ac-4bf6-b307-cc24faf5e65c",
    "outputId": "5dd1d499-96c6-45df-fedd-fca2a5d1d237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#--- hyperparameter ---\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# cross-validation\n",
    "N_SPLITS = 5 # number of folds\n",
    "FOLD = 0 # which fold for validation\n",
    "\n",
    "# sequence length\n",
    "K = 50 # number of events to consider before the target event if smaller than K, pad with zeros\n",
    "MIN_EVENTS = 2\n",
    "\n",
    "# training parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# model parameters\n",
    "HIDDEN_SIZE = 256 # LSTM hidden size\n",
    "NUM_LAYERS = 2 # number of LSTM layers\n",
    "DROPOUT = 0.4  # increased from 0.2 for regularization\n",
    "NUM_HEADS = 4 # number of attention heads for multi-head attention\n",
    "\n",
    "# augmentation parameters\n",
    "NOISE_STD = 0.5  # std for coordinate noise augmentation (meters)\n",
    "\n",
    "# data loader parameters\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6953d-8cc2-424d-b9b1-d8b909c508fd",
   "metadata": {
    "id": "08a6953d-8cc2-424d-b9b1-d8b909c508fd"
   },
   "source": [
    "## 3. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5767755-4f5c-400f-a5d9-ce0d28912a88",
   "metadata": {
    "id": "d5767755-4f5c-400f-a5d9-ce0d28912a88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15435/15435 [00:09<00:00, 1656.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num episodes: 15428\n",
      "example cont shape: (49, 12) | example target: [97.13403 41.79307]\n",
      "\\nfeatures check:\n",
      "  cont_dim (should be 12): 12\n",
      "  prev_valid[0] (should be 0): 0.0\n",
      "  prev_valid[1] (should be 1): 1.0\n",
      "  prev_dx[1]: -21.0958, prev_dy[1]: 4.7893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "# sort events inside each episode by time, then action_id\n",
    "# action_id is used for duplicate time_seconds\n",
    "df = df.sort_values([\"game_episode\", \"time_seconds\", \"action_id\"]).reset_index(drop=True)\n",
    "\n",
    "# fill missing category text\n",
    "df[\"type_name\"] = df[\"type_name\"].fillna(\"__NA_TYPE__\")\n",
    "df[\"result_name\"] = df[\"result_name\"].fillna(\"__NA_RES__\")\n",
    "\n",
    "# change category text to idx(number)\n",
    "# mapping number is just name, no matter with performance\n",
    "le_type = LabelEncoder()\n",
    "le_res  = LabelEncoder()\n",
    "# id: number idx, name: text category\n",
    "df[\"type_id\"] = le_type.fit_transform(df[\"type_name\"]) + 1 # start from 1 to avoid 0 for padding\n",
    "df[\"res_id\"]  = le_res.fit_transform(df[\"result_name\"]) + 1\n",
    "\n",
    "# stadium (105 x 68), attacking direction: left -> right\n",
    "STADIUM_X, STADIUM_Y = 105.0, 68.0\n",
    "CENTER_Y = STADIUM_Y / 2.0  # 34.0\n",
    "HALF_X   = STADIUM_X / 2.0  # 52.5\n",
    "\n",
    "# goal position\n",
    "GOAL_X, GOAL_Y = STADIUM_X, CENTER_Y  # (105.0, 34.0)\n",
    "\n",
    "# goal segment (FIFA goal width 7.32m => +/-3.66m from center)\n",
    "GOAL_POST_HALF = 3.66\n",
    "GOAL_Y_L = CENTER_Y - GOAL_POST_HALF  # 30.34\n",
    "GOAL_Y_R = CENTER_Y + GOAL_POST_HALF  # 37.66\n",
    "\n",
    "\n",
    "# opponent penalty box (FIFA: 16.5m deep, 40.32m wide => +/-20.16m from center)\n",
    "P_BOX_X_MIN = STADIUM_X - 16.5        # 88.5\n",
    "P_BOX_Y_MIN = CENTER_Y - 20.16      # 13.84\n",
    "P_BOX_Y_MAX = CENTER_Y + 20.16      # 54.16\n",
    "\n",
    "episodes = [] # list of episodes' event sequences\n",
    "targets  = [] # list of target (x,y) per episode\n",
    "episode_keys = [] # ex) 12345_7 used for game_episode rematching, debug\n",
    "episode_game_ids = [] # gmae_id list\n",
    "\n",
    "# build sequences per game_episode\n",
    "for key, g in tqdm(df.groupby(\"game_episode\")): # key: {game_id}_{episode_id}, g: features in the episode + type_id, res_id\n",
    "    g = g.reset_index(drop=True) # realign index [0 ... T-1]\n",
    "    if len(g) < 2:\n",
    "        continue\n",
    "\n",
    "    # target data is the last Pass event's end point\n",
    "    # if not pass event in the episode, skip, actually only one case of carry\n",
    "    if g.iloc[-1][\"type_name\"] != \"Pass\":\n",
    "        pass_idxs = g.index[g[\"type_name\"] == \"Pass\"]\n",
    "        if len(pass_idxs) == 0:\n",
    "            continue\n",
    "        g = g.loc[:pass_idxs[-1]].reset_index(drop=True)\n",
    "\n",
    "        # after cutting, ensure enough length\n",
    "        if len(g) < 2:\n",
    "            continue\n",
    "\n",
    "    # target is the last event's end point\n",
    "    tx, ty = float(g.loc[len(g)-1, \"end_x\"]), float(g.loc[len(g)-1, \"end_y\"])\n",
    "    if np.isnan(tx) or np.isnan(ty):\n",
    "        continue\n",
    "\n",
    "    # compute dt inside episode\n",
    "    t = g[\"time_seconds\"].astype(\"float32\").values\n",
    "    dt = np.zeros_like(t, dtype=\"float32\")\n",
    "    dt[1:] = t[1:] - t[:-1]\n",
    "    dt[dt < 0] = 0.0  # time-reversal safe-guard\n",
    "\n",
    "    # extract start/end positions\n",
    "    sx = g[\"start_x\"].astype(\"float32\").values\n",
    "    sy = g[\"start_y\"].astype(\"float32\").values\n",
    "    ex = g[\"end_x\"].astype(\"float32\").values\n",
    "    ey = g[\"end_y\"].astype(\"float32\").values\n",
    "\n",
    "    # leak-safe masking for last event's end\n",
    "    ex_mask = ex.copy() \n",
    "    ey_mask = ey.copy()\n",
    "    ex_mask[-1] = 0.0 # leak-safe\n",
    "    ey_mask[-1] = 0.0 # leak-safe\n",
    "\n",
    "    # goal geometry features\n",
    "    dxg = GOAL_X - sx  # delta x to goal line\n",
    "    dy_goal = np.maximum(0.0, np.maximum(GOAL_Y_L - sy, sy - GOAL_Y_R)) # delta y to goal segment, if inside segment = 0, else minimum y distance\n",
    "    dist_to_goal = np.sqrt(dxg**2 + dy_goal**2).astype(\"float32\") # distance to goal segment\n",
    "\n",
    "    # angles to goal posts\n",
    "    alpha_L = np.arctan2(GOAL_Y_L - sy, dxg).astype(\"float32\")\n",
    "    alpha_R = np.arctan2(GOAL_Y_R - sy, dxg).astype(\"float32\")\n",
    "\n",
    "    # goal view features\n",
    "    theta_view = np.abs(alpha_R - alpha_L).astype(\"float32\")\n",
    "\n",
    "    # half line\n",
    "    in_own_half = (sx < HALF_X).astype(\"float32\") # (1): own half, (0): opponent half\n",
    "\n",
    "    # penalty box (only dist_p_box, removed in_p_box)\n",
    "    dx_box = np.maximum(0.0, P_BOX_X_MIN - sx) # inside: 0, outside: delta x to penalty box\n",
    "    dy_box = np.maximum(0.0, np.maximum(P_BOX_Y_MIN - sy, sy - P_BOX_Y_MAX)) # inside 0, outside: delta y to penalty box\n",
    "    dist_p_box = np.sqrt(dx_box**2 + dy_box**2).astype(\"float32\") # distance to penalty box\n",
    "\n",
    "    # previous event features\n",
    "    # prev_dx[t] = end_x[t-1] - start_x[t-1], prev_dy[t] = end_y[t-1] - start_y[t-1]\n",
    "    # [when t = 0 (no prev case)] 0, prev_valid=0\n",
    "    T = len(g)\n",
    "    prev_dx = np.zeros(T, dtype=\"float32\")\n",
    "    prev_dy = np.zeros(T, dtype=\"float32\")\n",
    "    prev_valid = np.zeros(T, dtype=\"float32\")\n",
    "\n",
    "    if T > 1:\n",
    "        # movement for prev event (t-1's end - start)\n",
    "        dx_prev_raw = ex[:-1] - sx[:-1]  # shape (T-1,)\n",
    "        dy_prev_raw = ey[:-1] - sy[:-1]\n",
    "\n",
    "        # assign on t>=1\n",
    "        prev_dx[1:] = dx_prev_raw\n",
    "        prev_dy[1:] = dy_prev_raw\n",
    "        prev_valid[1:] = 1.0\n",
    "\n",
    "    # categorical idx per event\n",
    "    type_id = g[\"type_id\"].astype(\"int64\").values\n",
    "    res_id  = g[\"res_id\"].astype(\"int64\").values\n",
    "\n",
    "    # continuous features per event (T, F_cont)\n",
    "    # x,y -> start_x,start_y\n",
    "    # end_x,end_y -> masked for last event\n",
    "    # dt -> time gap\n",
    "    # is_start,is_end -> flags\n",
    "    # dist_to_goal, angle_to_goal -> geometry\n",
    "    cont = np.stack(\n",
    "        [\n",
    "            sx,            # 1\n",
    "            sy,            # 2\n",
    "            ex_mask,       # 3\n",
    "            ey_mask,       # 4\n",
    "            dt,            # 5\n",
    "            dist_to_goal,  # 6\n",
    "            theta_view,    # 7\n",
    "            in_own_half,   # 8\n",
    "            dist_p_box,    # 9\n",
    "            prev_dx,       # 10\n",
    "            prev_dy,       # 11\n",
    "            prev_valid     # 12\n",
    "        ],\n",
    "        axis=1\n",
    "    ).astype(\"float32\")  # (T, F_cont)\n",
    "\n",
    "    episodes.append({\n",
    "        \"cont\": cont,               # continuous features\n",
    "        \"type_id\": type_id,         # categorical type idx\n",
    "        \"res_id\": res_id            # categorical result idx\n",
    "    })\n",
    "\n",
    "    targets.append(np.array([tx, ty], dtype=\"float32\"))  # target (x,y)\n",
    "    episode_keys.append(key)  # for rematching\n",
    "    episode_game_ids.append(key.split(\"_\")[0])  # game_id only\n",
    "\n",
    "\n",
    "print(\"num episodes:\", len(episodes))\n",
    "print(\"example cont shape:\", episodes[0][\"cont\"].shape, \"| example target:\", targets[0])\n",
    "\n",
    "# debug\n",
    "sample_cont = episodes[0][\"cont\"]\n",
    "print(\"\\\\nfeatures check:\")\n",
    "print(f\"  cont_dim (should be 12): {sample_cont.shape[1]}\")\n",
    "print(f\"  prev_valid[0] (should be 0): {sample_cont[0, 11]}\")\n",
    "if sample_cont.shape[0] > 1:\n",
    "    print(f\"  prev_valid[1] (should be 1): {sample_cont[1, 11]}\")\n",
    "    print(f\"  prev_dx[1]: {sample_cont[1, 9]:.4f}, prev_dy[1]: {sample_cont[1, 10]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66140869-2d3c-460d-8678-ae6d23d97b88",
   "metadata": {
    "id": "66140869-2d3c-460d-8678-ae6d23d97b88"
   },
   "source": [
    "## 4. Custom Dataset / DataLoader 정의 및 Validation 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b1b1d3-851b-4d29-8130-a14410345661",
   "metadata": {
    "id": "c6b1b1d3-851b-4d29-8130-a14410345661",
    "outputId": "1ac9bd9b-3a85-4d37-8cc5-e2c72282b1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train episodes: 12320 | valid episodes: 3108\n",
      "batch cont_pad: (256, 173, 12)\n",
      "batch type_pad: (256, 173)\n",
      "batch res_pad: (256, 173)\n",
      "lengths: (256,)\n",
      "y: (256, 2)\n",
      "example key: 126357_49\n"
     ]
    }
   ],
   "source": [
    "class EpisodeDataset(Dataset):\n",
    "    # store sequences and targets, give tuple(묶음) by idx\n",
    "\n",
    "    def __init__(self, episodes, targets, keys, augment=False, noise_std=0.0):\n",
    "        self.episodes = episodes # episodes: list of dict(cont, type_id, res_id)\n",
    "        self.targets = targets # targets: list of (x,y)\n",
    "        self.keys = keys  # ex) 12345_7 used for game_episode rematching, debug\n",
    "        self.augment = augment  # whether to apply augmentation\n",
    "        self.noise_std = noise_std  # noise std for coordinates\n",
    "\n",
    "    # number of episodes\n",
    "    def __len__(self):\n",
    "        return len(self.episodes)\n",
    "\n",
    "    # return one episode as tensor [cont, type_id, res_id, y, key]\n",
    "    def __getitem__(self, idx):\n",
    "        ep = self.episodes[idx]                             # episode dict, includes below\n",
    "        cont = ep[\"cont\"].copy()                            # copy to avoid modifying original\n",
    "        \n",
    "        # augmentation: add noise to coordinates (sx, sy, ex_mask, ey_mask)\n",
    "        if self.augment and self.noise_std > 0:\n",
    "            noise = np.random.randn(cont.shape[0], 4).astype(\"float32\") * self.noise_std\n",
    "            cont[:, 0:4] += noise  # sx, sy, ex_mask, ey_mask\n",
    "            # clamp to valid stadium range\n",
    "            cont[:, 0] = np.clip(cont[:, 0], 0, 105)  # sx\n",
    "            cont[:, 1] = np.clip(cont[:, 1], 0, 68)   # sy\n",
    "            cont[:, 2] = np.clip(cont[:, 2], 0, 105)  # ex_mask\n",
    "            cont[:, 3] = np.clip(cont[:, 3], 0, 68)   # ey_mask\n",
    "        \n",
    "        cont = torch.from_numpy(cont)                       # features tensor\n",
    "        type_id = torch.from_numpy(ep[\"type_id\"])           # type_name tensor\n",
    "        res_id  = torch.from_numpy(ep[\"res_id\"])            # res_id tensor\n",
    "        y = torch.from_numpy(self.targets[idx])             # target tensor\n",
    "        key = self.keys[idx]                                # for debug\n",
    "        return cont, type_id, res_id, y, key                # tuple: (cont, type_id, res_id, y, key)\n",
    "\n",
    "# collate(합치다) variable-length samples into a padded batch\n",
    "def collate_fn(batch):\n",
    "    # unpack tuple list\n",
    "    conts, type_ids, res_ids, ys, keys = zip(*batch)\n",
    "\n",
    "    # lengths before padding\n",
    "    lengths = torch.tensor([c.shape[0] for c in conts], dtype=torch.long)\n",
    "\n",
    "    # pad to max length in batch\n",
    "    cont_pad = pad_sequence(conts, batch_first=True, padding_value=0.0)       # (B, T_max, F)\n",
    "    type_pad = pad_sequence(type_ids, batch_first=True, padding_value=0)      # (B, T_max)\n",
    "    res_pad  = pad_sequence(res_ids,  batch_first=True, padding_value=0)      # (B, T_max)\n",
    "    y = torch.stack(ys, dim=0).float()                                        # (B, 2)\n",
    "\n",
    "    return cont_pad.float(), type_pad.long(), res_pad.long(), lengths, y, keys # to verify padded length\n",
    "\n",
    "# split train/valid\n",
    "episode_game_ids = np.array(episode_game_ids, dtype=np.int64) # convert game_id list to numpy array\n",
    "\n",
    "# ex) 10 game_ids -> 2,2,2,2,2 for 5-fold\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "# FOLDth idx -> for validation, rest for training\n",
    "tr_idx, va_idx = None, None\n",
    "for fold_i, (tr, va) in enumerate(\n",
    "    gkf.split(\n",
    "        np.zeros(len(episodes)),  # dummy X\n",
    "        np.zeros(len(episodes)),  # dummy y\n",
    "        groups=episode_game_ids   # group key\n",
    "    )\n",
    "):\n",
    "    if fold_i == FOLD:\n",
    "        tr_idx, va_idx = tr, va\n",
    "        break\n",
    "\n",
    "# Defensive check for fold selection.\n",
    "assert tr_idx is not None and va_idx is not None, \"Fold selection failed. Check FOLD and N_SPLITS.\"\n",
    "\n",
    "# build train split datasets from tr_idx\n",
    "train_eps = [episodes[i] for i in tr_idx]\n",
    "train_tg  = [targets[i]  for i in tr_idx]\n",
    "train_keys= [episode_keys[i] for i in tr_idx]\n",
    "\n",
    "# build valid split datasets from va_idx\n",
    "valid_eps = [episodes[i] for i in va_idx]\n",
    "valid_tg  = [targets[i]  for i in va_idx]\n",
    "valid_keys= [episode_keys[i] for i in va_idx]\n",
    "\n",
    "# Dataset: 문제집\n",
    "train_ds = EpisodeDataset(train_eps, train_tg, train_keys, augment=True, noise_std=NOISE_STD)\n",
    "valid_ds = EpisodeDataset(valid_eps, valid_tg, valid_keys, augment=False)  # no augment for valid\n",
    "\n",
    "# DataLoader: 문제집의 문제\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn) # train: shuffle\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn) # valid: no shuffle\n",
    "\n",
    "# print dataset sizes\n",
    "print(\"train episodes:\", len(train_ds), \"| valid episodes:\", len(valid_ds))\n",
    "# get one batch for debug\n",
    "cont_pad, type_pad, res_pad, lengths, y, keys = next(iter(train_loader))\n",
    "print(\"batch cont_pad:\", tuple(cont_pad.shape)) # [B, T_max, F]\n",
    "print(\"batch type_pad:\", tuple(type_pad.shape)) # [B, T_max]\n",
    "print(\"batch res_pad:\", tuple(res_pad.shape))   # [B, T_max]\n",
    "print(\"lengths:\", tuple(lengths.shape))         # [B]\n",
    "print(\"y:\", tuple(y.shape))                     # [B, 2]\n",
    "print(\"example key:\", keys[0])                  # ex) 12345_7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4f89e-808e-41eb-bbc3-db4a32fab6a8",
   "metadata": {
    "id": "a0d4f89e-808e-41eb-bbc3-db4a32fab6a8"
   },
   "source": [
    "## 5. LSTM 베이스라인 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef323dcf-0a45-4323-ad8e-5bc8ed6c50f1",
   "metadata": {
    "id": "ef323dcf-0a45-4323-ad8e-5bc8ed6c50f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "n_type: 27 n_res: 10 cont_dim: 12 num_heads: 4\n"
     ]
    }
   ],
   "source": [
    "class PassLSTM(nn.Module):\n",
    "    # lstm for sequence regression with multi-head attention pooling\n",
    "    def __init__(self, cont_dim, n_type, n_res, emb_dim=16, hidden=256, num_layers=NUM_LAYERS, dropout=DROPOUT, num_heads=NUM_HEADS):\n",
    "        super().__init__()\n",
    "\n",
    "        # number to learnable vectors(embeddings)\n",
    "        self.type_emb = nn.Embedding(n_type, emb_dim, padding_idx=0)\n",
    "        self.res_emb  = nn.Embedding(n_res,  emb_dim, padding_idx=0)\n",
    "\n",
    "        # in_dim = cont + type_emb + res_emb\n",
    "        in_dim = cont_dim + emb_dim + emb_dim\n",
    "        \n",
    "        # Batch normalization for input features\n",
    "        self.input_bn = nn.BatchNorm1d(in_dim)\n",
    "\n",
    "        # lstm backbone\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=in_dim,\n",
    "            hidden_size=hidden, # memory\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0, # no dropout if single layer\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # Batch normalization after LSTM\n",
    "        self.lstm_bn = nn.BatchNorm1d(hidden)\n",
    "        \n",
    "        self.hidden = hidden\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden // num_heads\n",
    "        \n",
    "        assert hidden % num_heads == 0, \"hidden must be divisible by num_heads\"\n",
    "        \n",
    "        # multi-head attention: each head learns different importance patterns\n",
    "        self.attn_heads = nn.ModuleList([\n",
    "            nn.Linear(hidden, 1, bias=False) for _ in range(num_heads)\n",
    "        ])\n",
    "        \n",
    "        # projection after concatenating heads\n",
    "        self.head_proj = nn.Linear(hidden * num_heads, hidden)\n",
    "        \n",
    "        # Batch normalization after head projection\n",
    "        self.head_proj_bn = nn.BatchNorm1d(hidden)\n",
    "        \n",
    "        # layer norm for stability\n",
    "        self.layer_norm = nn.LayerNorm(hidden)\n",
    "\n",
    "        # regression head -> (x,y)\n",
    "        # receive pooled hidden state and output (x,y)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),  # Added BN\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 2) # (x,y)\n",
    "        )\n",
    "\n",
    "    # forward pass with multi-head attention pooling\n",
    "    # embed -> concat -> pack -> lstm -> unpack -> multi-head attention pool -> head\n",
    "    def forward(self, cont_pad, type_pad, res_pad, lengths):\n",
    "        # embed categories\n",
    "        te = self.type_emb(type_pad)  # (B,T,emb)\n",
    "        re = self.res_emb(res_pad)    # (B,T,emb)\n",
    "\n",
    "        # concat all features\n",
    "        x = torch.cat([cont_pad, te, re], dim=-1)  # (B,T,in_dim)\n",
    "        \n",
    "        # Apply batch normalization to input features\n",
    "        # Reshape for BatchNorm1d: (B, T, F) -> (B*T, F) -> BN -> (B, T, F)\n",
    "        B, T, F = x.shape\n",
    "        x_flat = x.view(B*T, F)\n",
    "        x_flat = self.input_bn(x_flat)\n",
    "        x = x_flat.view(B, T, F)\n",
    "\n",
    "        # pack padded sequence to ignore padding steps\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        # unpack to get all timestep outputs for pooling\n",
    "        outputs, _ = pad_packed_sequence(packed_out, batch_first=True)  # (B, T, H)\n",
    "        \n",
    "        # Apply batch normalization to LSTM outputs\n",
    "        B, T, H = outputs.shape\n",
    "        outputs_flat = outputs.contiguous().view(B*T, H)\n",
    "        outputs_flat = self.lstm_bn(outputs_flat)\n",
    "        outputs = outputs_flat.view(B, T, H)\n",
    "        \n",
    "        # mask: True for valid timesteps, False for padding\n",
    "        idx = torch.arange(T, device=outputs.device).unsqueeze(0)       # (1, T)\n",
    "        mask = (idx < lengths.unsqueeze(1))                             # (B, T) bool\n",
    "        \n",
    "        # multi-head attention pooling\n",
    "        head_outputs = []\n",
    "        for attn_layer in self.attn_heads:\n",
    "            # attention scores for this head\n",
    "            scores = attn_layer(outputs).squeeze(-1)                    # (B, T)\n",
    "            \n",
    "            # mask padding positions with -inf before softmax\n",
    "            scores = scores.masked_fill(~mask, float('-inf'))           # (B, T)\n",
    "            \n",
    "            # attention weights (softmax over valid timesteps)\n",
    "            attn_weights = torch.softmax(scores, dim=1)                 # (B, T)\n",
    "            \n",
    "            # handle all-padding edge case\n",
    "            attn_weights = torch.nan_to_num(attn_weights, nan=0.0)\n",
    "            \n",
    "            # weighted sum for this head\n",
    "            pooled_head = torch.bmm(attn_weights.unsqueeze(1), outputs).squeeze(1)  # (B, H)\n",
    "            head_outputs.append(pooled_head)\n",
    "        \n",
    "        # concatenate all heads and project\n",
    "        multi_head = torch.cat(head_outputs, dim=-1)  # (B, H * num_heads)\n",
    "        pooled = self.head_proj(multi_head)           # (B, H)\n",
    "        \n",
    "        # Apply batch normalization to head projection\n",
    "        pooled = self.head_proj_bn(pooled)\n",
    "        \n",
    "        # layer normalization\n",
    "        pooled = self.layer_norm(pooled)\n",
    "        \n",
    "        # predict from multi-head attention-pooled representation\n",
    "        out = self.head(pooled)  # (B, 2)\n",
    "        return out\n",
    "\n",
    "# sizes for embeddings\n",
    "n_type = len(le_type.classes_) + 1  # +1 for padding idx=0\n",
    "n_res  = len(le_res.classes_)  + 1  # +1 for padding idx=0\n",
    "cont_dim = int(episodes[0][\"cont\"].shape[1])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PassLSTM(\n",
    "                cont_dim=cont_dim, \n",
    "                n_type=n_type, \n",
    "                n_res=n_res, \n",
    "                emb_dim=16, \n",
    "                hidden=HIDDEN_SIZE, \n",
    "                num_layers=NUM_LAYERS, \n",
    "                dropout=DROPOUT,\n",
    "                num_heads=NUM_HEADS\n",
    "                ).to(device)\n",
    "\n",
    "print(\"device:\", device)\n",
    "print(\"n_type:\", n_type, \"n_res:\", n_res, \"cont_dim:\", cont_dim, \"num_heads:\", NUM_HEADS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fca4d7-cd45-4140-bc42-deb004be7976",
   "metadata": {
    "id": "f3fca4d7-cd45-4140-bc42-deb004be7976"
   },
   "source": [
    "## 6. 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a302ea7-6c5b-4f39-b24d-e1403aa091db",
   "metadata": {
    "id": "7a302ea7-6c5b-4f39-b24d-e1403aa091db",
    "outputId": "51c8ed22-b8ac-4f20-ea86-365a1440970e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] lr=1.00e-03 | train_loss=33.5499 | train_euclid_dist=53.5278 | valid_euclid_dist=32.3586 | gap = -21.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] lr=1.00e-03 | train_loss=19.0856 | train_euclid_dist=30.4629 | valid_euclid_dist=27.2628 | gap = -3.2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] lr=1.00e-03 | train_loss=16.3784 | train_euclid_dist=26.3420 | valid_euclid_dist=22.6148 | gap = -3.7271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] lr=1.00e-03 | train_loss=11.9031 | train_euclid_dist=19.5270 | valid_euclid_dist=16.6403 | gap = -2.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] lr=1.00e-03 | train_loss=10.6457 | train_euclid_dist=17.6291 | valid_euclid_dist=15.9122 | gap = -1.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] lr=1.00e-03 | train_loss=10.3321 | train_euclid_dist=17.1774 | valid_euclid_dist=15.7400 | gap = -1.4374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] lr=1.00e-03 | train_loss=10.1565 | train_euclid_dist=16.8880 | valid_euclid_dist=15.6325 | gap = -1.2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] lr=1.00e-03 | train_loss=9.9876 | train_euclid_dist=16.6126 | valid_euclid_dist=15.1342 | gap = -1.4784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] lr=1.00e-03 | train_loss=9.9255 | train_euclid_dist=16.5371 | valid_euclid_dist=14.7263 | gap = -1.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] lr=1.00e-03 | train_loss=9.8349 | train_euclid_dist=16.3697 | valid_euclid_dist=14.8833 | gap = -1.4864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] lr=1.00e-03 | train_loss=9.7159 | train_euclid_dist=16.2093 | valid_euclid_dist=14.9557 | gap = -1.2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] lr=1.00e-03 | train_loss=9.6310 | train_euclid_dist=16.0900 | valid_euclid_dist=14.9766 | gap = -1.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] lr=1.00e-03 | train_loss=9.5679 | train_euclid_dist=15.9620 | valid_euclid_dist=14.6931 | gap = -1.2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14] lr=1.00e-03 | train_loss=9.5717 | train_euclid_dist=15.9844 | valid_euclid_dist=14.4076 | gap = -1.5768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] lr=1.00e-03 | train_loss=9.4340 | train_euclid_dist=15.7920 | valid_euclid_dist=14.8347 | gap = -0.9573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] lr=1.00e-03 | train_loss=9.4521 | train_euclid_dist=15.7861 | valid_euclid_dist=14.6356 | gap = -1.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17] lr=1.00e-03 | train_loss=9.4050 | train_euclid_dist=15.7096 | valid_euclid_dist=14.6256 | gap = -1.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] lr=1.00e-03 | train_loss=9.3766 | train_euclid_dist=15.6696 | valid_euclid_dist=14.4739 | gap = -1.1956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19] lr=1.00e-03 | train_loss=9.3599 | train_euclid_dist=15.6493 | valid_euclid_dist=14.6080 | gap = -1.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20] lr=1.00e-03 | train_loss=9.3111 | train_euclid_dist=15.5809 | valid_euclid_dist=14.4408 | gap = -1.1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21] lr=1.00e-03 | train_loss=9.1969 | train_euclid_dist=15.3899 | valid_euclid_dist=14.1714 | gap = -1.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 22] lr=1.00e-03 | train_loss=9.2282 | train_euclid_dist=15.4401 | valid_euclid_dist=14.2671 | gap = -1.1730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23] lr=1.00e-03 | train_loss=9.0956 | train_euclid_dist=15.2366 | valid_euclid_dist=14.3070 | gap = -0.9295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24] lr=1.00e-03 | train_loss=9.1989 | train_euclid_dist=15.3881 | valid_euclid_dist=14.1465 | gap = -1.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 25] lr=1.00e-03 | train_loss=9.0890 | train_euclid_dist=15.2190 | valid_euclid_dist=14.2878 | gap = -0.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 26] lr=1.00e-03 | train_loss=9.0818 | train_euclid_dist=15.2419 | valid_euclid_dist=14.4248 | gap = -0.8172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27] lr=1.00e-03 | train_loss=9.0655 | train_euclid_dist=15.2131 | valid_euclid_dist=14.2906 | gap = -0.9224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28] lr=1.00e-03 | train_loss=9.0332 | train_euclid_dist=15.1604 | valid_euclid_dist=14.4345 | gap = -0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     31\u001b[39m tr_euc_cnt  = \u001b[32m0\u001b[39m\n\u001b[32m     33\u001b[39m train_pbar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcont_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_pbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcont_pad\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcont_pad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_pad\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_pad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mEpisodeDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     23\u001b[39m cont[:, \u001b[32m0\u001b[39m:\u001b[32m4\u001b[39m] += noise  \u001b[38;5;66;03m# sx, sy, ex_mask, ey_mask\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# clamp to valid stadium range\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m cont[:, \u001b[32m0\u001b[39m] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcont\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m105\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# sx\u001b[39;00m\n\u001b[32m     26\u001b[39m cont[:, \u001b[32m1\u001b[39m] = np.clip(cont[:, \u001b[32m1\u001b[39m], \u001b[32m0\u001b[39m, \u001b[32m68\u001b[39m)   \u001b[38;5;66;03m# sy\u001b[39;00m\n\u001b[32m     27\u001b[39m cont[:, \u001b[32m2\u001b[39m] = np.clip(cont[:, \u001b[32m2\u001b[39m], \u001b[32m0\u001b[39m, \u001b[32m105\u001b[39m)  \u001b[38;5;66;03m# ex_mask\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:2236\u001b[39m, in \u001b[36m_clip_dispatcher\u001b[39m\u001b[34m(a, a_min, a_max, out, min, max, **kwargs)\u001b[39m\n\u001b[32m   2173\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2174\u001b[39m \u001b[33;03m    Return selected slices of an array along given axis.\u001b[39;00m\n\u001b[32m   2175\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2231\u001b[39m \n\u001b[32m   2232\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mcompress\u001b[39m\u001b[33m'\u001b[39m, condition, axis=axis, out=out)\n\u001b[32m-> \u001b[39m\u001b[32m2236\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_clip_dispatcher\u001b[39m(a, a_min=\u001b[38;5;28;01mNone\u001b[39;00m, a_max=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, *, \u001b[38;5;28mmin\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2237\u001b[39m                      \u001b[38;5;28mmax\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, a_min, a_max, out, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m)\n\u001b[32m   2241\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n\u001b[32m   2242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclip\u001b[39m(a, a_min=np._NoValue, a_max=np._NoValue, out=\u001b[38;5;28;01mNone\u001b[39;00m, *,\n\u001b[32m   2243\u001b[39m          \u001b[38;5;28mmin\u001b[39m=np._NoValue, \u001b[38;5;28mmax\u001b[39m=np._NoValue, **kwargs):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def euclidean_sum_and_count(pred, true):\n",
    "    # EN: Return sum of Euclidean distances and sample count.\n",
    "    # KR: 유클리드 거리 합과 샘플 수를 반환해서 “샘플 기준 평균”을 정확히 계산한다.\n",
    "    d = torch.sqrt(((pred - true) ** 2).sum(dim=1))  # (B,)\n",
    "    return d.sum().item(), d.numel()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "# LR Scheduler: ReduceLROnPlateau (valid 기준)\n",
    "# valid가 patience epoch 동안 개선 안 되면 lr을 factor만큼 줄임\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',       # minimize valid distance\n",
    "    factor=0.5,       # lr *= 0.5 when plateau\n",
    "    patience=10,      # wait 10 epochs before reducing\n",
    "    min_lr=1e-6       # minimum learning rate\n",
    ")\n",
    "\n",
    "best_val = 1e9\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "\n",
    "    # EN: Accumulators for weighted means.\n",
    "    # KR: 샘플 수로 가중 평균을 내기 위한 누적 변수들이다.\n",
    "    tr_loss_sum = 0.0\n",
    "    tr_loss_cnt = 0\n",
    "    tr_euc_sum  = 0.0\n",
    "    tr_euc_cnt  = 0\n",
    "\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\", leave=False)\n",
    "\n",
    "    for cont_pad, type_pad, res_pad, lengths, y, keys in train_pbar:\n",
    "        cont_pad = cont_pad.to(device)\n",
    "        type_pad = type_pad.to(device)\n",
    "        res_pad  = res_pad.to(device)\n",
    "        lengths  = lengths.to(device)\n",
    "        y        = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(cont_pad, type_pad, res_pad, lengths)\n",
    "\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # EN: Weighted mean for SmoothL1.\n",
    "        # KR: SmoothL1Loss는 배치 평균 스칼라이므로, 샘플 수로 다시 가중해 누적한다.\n",
    "        bsz = y.size(0)\n",
    "        tr_loss_sum += loss.item() * bsz\n",
    "        tr_loss_cnt += bsz\n",
    "\n",
    "        # EN: Also log train Euclidean distance (metric-aligned).\n",
    "        # KR: train에서도 대회 지표인 유클리드 거리를 함께 누적해서 원인 분석이 가능해진다.\n",
    "        e_sum, e_cnt = euclidean_sum_and_count(pred.detach(), y)\n",
    "        tr_euc_sum  += e_sum\n",
    "        tr_euc_cnt  += e_cnt\n",
    "\n",
    "        train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_euc_sum = 0.0\n",
    "    val_euc_cnt = 0\n",
    "\n",
    "    valid_pbar = tqdm(valid_loader, desc=f\"Valid {epoch}/{EPOCHS}\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cont_pad, type_pad, res_pad, lengths, y, keys in valid_pbar:\n",
    "            cont_pad = cont_pad.to(device)\n",
    "            type_pad = type_pad.to(device)\n",
    "            res_pad  = res_pad.to(device)\n",
    "            lengths  = lengths.to(device)\n",
    "            y        = y.to(device)\n",
    "\n",
    "            pred = model(cont_pad, type_pad, res_pad, lengths)\n",
    "            e_sum, e_cnt = euclidean_sum_and_count(pred, y)\n",
    "            val_euc_sum += e_sum\n",
    "            val_euc_cnt += e_cnt\n",
    "\n",
    "            valid_pbar.set_postfix(dist=f\"{(e_sum / max(e_cnt, 1)):.4f}\")\n",
    "\n",
    "    tr_loss  = tr_loss_sum / max(tr_loss_cnt, 1)\n",
    "    tr_euc   = tr_euc_sum  / max(tr_euc_cnt, 1)\n",
    "    val_dist = val_euc_sum / max(val_euc_cnt, 1)\n",
    "    \n",
    "    # step scheduler based on validation metric\n",
    "    scheduler.step(val_dist)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # gap: valid - train euclid dist -> minus: good, plus: overfit\n",
    "    print(f\"[epoch {epoch}] lr={current_lr:.2e} | train_loss={tr_loss:.4f} | train_euclid_dist={tr_euc:.4f} | valid_euclid_dist={val_dist:.4f} | gap = {(val_dist - tr_euc):.4f}\")\n",
    "\n",
    "    if val_dist < best_val:\n",
    "        best_val = val_dist\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(\"best valid_euclid_dist:\", best_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ddd96-c48d-432e-88ac-3872549e9857",
   "metadata": {
    "id": "1d2ddd96-c48d-432e-88ac-3872549e9857"
   },
   "source": [
    "## 7. 평가 데이터셋 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b3009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best valid_euclid_dist: 13.886074679852145\n"
     ]
    }
   ],
   "source": [
    "if val_dist < best_val:\n",
    "        best_val = val_dist\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(\"best valid_euclid_dist:\", best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6849ef5-efac-4cfa-9ead-73b1f4dc1760",
   "metadata": {
    "id": "f6849ef5-efac-4cfa-9ead-73b1f4dc1760",
    "outputId": "e45b143d-fa03-40b4-d30c-269b64ade5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference done: 2414\n"
     ]
    }
   ],
   "source": [
    "# read -> feature -> predict -> submit\n",
    "\n",
    "TEST_META_PATH = \"../data/test.csv\"\n",
    "SUBMISSION_PATH = \"../data/sample_submission.csv\"\n",
    "DATA_ROOT = \"../data\"\n",
    "\n",
    "# use the same geometry constants as training\n",
    "STADIUM_X, STADIUM_Y = 105.0, 68.0\n",
    "\n",
    "CENTER_Y = STADIUM_Y / 2.0  # 34.0\n",
    "HALF_X   = STADIUM_X / 2.0  # 52.5\n",
    "\n",
    "GOAL_X, GOAL_Y = STADIUM_X, CENTER_Y  # (105.0, 34.0)\n",
    "\n",
    "GOAL_POST_HALF = 3.66\n",
    "GOAL_Y_L = CENTER_Y - GOAL_POST_HALF  # 30.34\n",
    "GOAL_Y_R = CENTER_Y + GOAL_POST_HALF  # 37.66\n",
    "\n",
    "P_BOX_X_MIN = STADIUM_X - 16.5        # 88.5\n",
    "P_BOX_Y_MIN = CENTER_Y - 20.16        # 13.84\n",
    "P_BOX_Y_MAX = CENTER_Y + 20.16        # 54.16\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# inference = eval mode\n",
    "model.eval()\n",
    "\n",
    "# load test episode list and submission template.\n",
    "test_meta = pd.read_csv(TEST_META_PATH)\n",
    "submission = pd.read_csv(SUBMISSION_PATH)\n",
    "\n",
    "# build one episode features using the same preprocessing as training\n",
    "def build_episode_from_df(g):\n",
    "    # sort inside episode\n",
    "    g = g.sort_values([\"time_seconds\", \"action_id\"]).reset_index(drop=True)\n",
    "\n",
    "    # fill categories\n",
    "    g[\"type_name\"] = g[\"type_name\"].fillna(\"__NA_TYPE__\")\n",
    "    g[\"result_name\"] = g[\"result_name\"].fillna(\"__NA_RES__\")\n",
    "\n",
    "    # handle unseen labels safely\n",
    "    g.loc[~g[\"type_name\"].isin(le_type.classes_), \"type_name\"] = \"__NA_TYPE__\"\n",
    "    g.loc[~g[\"result_name\"].isin(le_res.classes_), \"result_name\"] = \"__NA_RES__\"\n",
    "\n",
    "    # Transform category strings into integer indices.\n",
    "    type_id = le_type.transform(g[\"type_name\"]).astype(\"int64\") + 1\n",
    "    res_id  = le_res.transform(g[\"result_name\"]).astype(\"int64\") + 1\n",
    "\n",
    "    # dt\n",
    "    t = g[\"time_seconds\"].astype(\"float32\").values\n",
    "    dt = np.zeros_like(t, dtype=\"float32\")\n",
    "    dt[1:] = t[1:] - t[:-1]\n",
    "    dt[dt < 0] = 0.0  # time-reversal safe-guard\n",
    "\n",
    "    # coordinates\n",
    "    sx = g[\"start_x\"].astype(\"float32\").values\n",
    "    sy = g[\"start_y\"].astype(\"float32\").values\n",
    "    ex = g[\"end_x\"].astype(\"float32\").values\n",
    "    ey = g[\"end_y\"].astype(\"float32\").values\n",
    "\n",
    "    # replace nan to 0.0\n",
    "    sx = np.nan_to_num(sx, nan=0.0)\n",
    "    sy = np.nan_to_num(sy, nan=0.0)\n",
    "    ex = np.nan_to_num(ex, nan=0.0)\n",
    "    ey = np.nan_to_num(ey, nan=0.0)\n",
    "\n",
    "    # mask last end for leak-safe\n",
    "    ex_mask = ex.copy()\n",
    "    ey_mask = ey.copy()\n",
    "    ex_mask[-1] = 0.0\n",
    "    ey_mask[-1] = 0.0\n",
    "\n",
    "    # goal segment distance\n",
    "    dxg = GOAL_X - sx\n",
    "    dy_goal = np.maximum(0.0, np.maximum(GOAL_Y_L - sy, sy - GOAL_Y_R)).astype(\"float32\")\n",
    "    dist_to_goal = np.sqrt(dxg**2 + dy_goal**2).astype(\"float32\")\n",
    "\n",
    "    # goal view angle\n",
    "    alpha_L = np.arctan2(GOAL_Y_L - sy, GOAL_X - sx).astype(\"float32\")\n",
    "    alpha_R = np.arctan2(GOAL_Y_R - sy, GOAL_X - sx).astype(\"float32\")\n",
    "    theta_view = np.abs(alpha_R - alpha_L).astype(\"float32\")\n",
    "\n",
    "    # half line features\n",
    "    in_own_half = (sx < HALF_X).astype(\"float32\")\n",
    "\n",
    "    # penalty box features\n",
    "    dx_box = np.maximum(0.0, P_BOX_X_MIN - sx).astype(\"float32\")\n",
    "    dy_box = np.maximum(0.0, np.maximum(P_BOX_Y_MIN - sy, sy - P_BOX_Y_MAX)).astype(\"float32\")\n",
    "    dist_p_box = np.sqrt(dx_box**2 + dy_box**2).astype(\"float32\")\n",
    "\n",
    "    # previous event features\n",
    "    T = len(g)\n",
    "    prev_dx = np.zeros(T, dtype=\"float32\")\n",
    "    prev_dy = np.zeros(T, dtype=\"float32\")\n",
    "    prev_valid = np.zeros(T, dtype=\"float32\")\n",
    "\n",
    "    if T > 1:\n",
    "        # movement for prev event (t-1's end - start)\n",
    "        dx_prev_raw = ex[:-1] - sx[:-1]  # shape (T-1,)\n",
    "        dy_prev_raw = ey[:-1] - sy[:-1]\n",
    "\n",
    "        # assign on t>=1\n",
    "        prev_dx[1:] = dx_prev_raw\n",
    "        prev_dy[1:] = dy_prev_raw\n",
    "        prev_valid[1:] = 1.0\n",
    "\n",
    "    # continuous features (must match training order)\n",
    "    cont = np.stack(\n",
    "        [\n",
    "            sx,            # 1\n",
    "            sy,            # 2\n",
    "            ex_mask,       # 3\n",
    "            ey_mask,       # 4\n",
    "            dt,            # 5\n",
    "            dist_to_goal,  # 6\n",
    "            theta_view,    # 7\n",
    "            in_own_half,   # 8\n",
    "            dist_p_box,    # 9\n",
    "            prev_dx,       # 10\n",
    "            prev_dy,       # 11\n",
    "            prev_valid     # 12\n",
    "        ],\n",
    "        axis=1\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "    return cont, type_id, res_id\n",
    "\n",
    "# predict for each episode and store results by key.\n",
    "pred_map = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, row in test_meta.iterrows():\n",
    "        game_episode = row[\"game_episode\"]\n",
    "\n",
    "        # test.csv has a column \"path\" like \"./test/153363/153363_1.csv\"\n",
    "        rel_path = str(row[\"path\"])\n",
    "        rel_path = rel_path[2:] if rel_path.startswith(\"./\") else rel_path\n",
    "        full_path = os.path.join(DATA_ROOT, rel_path)\n",
    "\n",
    "        # read one episode event file.\n",
    "        g = pd.read_csv(full_path)\n",
    "\n",
    "        # build features (cont, type_id, res_id).\n",
    "        cont, type_id, res_id = build_episode_from_df(g)\n",
    "\n",
    "        # convert arrays to tensors and add batch dim\n",
    "        cont_t = torch.from_numpy(cont).unsqueeze(0).to(device)     # (T,F) -> (1,T,F)\n",
    "        type_t = torch.from_numpy(type_id).unsqueeze(0).to(device)  # (T) -> (1,T)\n",
    "        res_t  = torch.from_numpy(res_id).unsqueeze(0).to(device)   # (T) -> (1,T)\n",
    "        lengths = torch.tensor([cont.shape[0]], dtype=torch.long).to(device) # true length\n",
    "        pred = model(cont_t.float(), type_t.long(), res_t.long(), lengths)  # (1,2)\n",
    "\n",
    "        pred_xy = pred.squeeze(0).detach().cpu().numpy().astype(\"float32\")\n",
    "\n",
    "        pred_map[game_episode] = pred_xy # prediction\n",
    "\n",
    "# align predictions to sample_submission order\n",
    "preds_x = []\n",
    "preds_y = []\n",
    "missing = []\n",
    "\n",
    "for ge in submission[\"game_episode\"].tolist():\n",
    "    # look up prediction by game_episode key.\n",
    "    if ge not in pred_map:\n",
    "        # handle missing predictions (should not happen)\n",
    "        missing.append(ge)\n",
    "        preds_x.append(0.0)\n",
    "        preds_y.append(0.0)\n",
    "        continue\n",
    "    px, py = pred_map[ge]\n",
    "    preds_x.append(float(px))\n",
    "    preds_y.append(float(py))\n",
    "\n",
    "if len(missing) > 0:\n",
    "    # Warn if any episodes are missing.\n",
    "    print(\"warning: missing episodes in pred_map:\", len(missing))\n",
    "\n",
    "# Assign predicted\n",
    "submission[\"end_x\"] = preds_x\n",
    "submission[\"end_y\"] = preds_y\n",
    "\n",
    "# Done inference for all rows.\n",
    "print(\"inference done:\", len(submission))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69009d4f-ed79-44e0-8ecf-8fd4e2cd0dd3",
   "metadata": {
    "id": "69009d4f-ed79-44e0-8ecf-8fd4e2cd0dd3"
   },
   "source": [
    "## 8. 제출 Submission 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: LSTM_2_submit_5.csv\n"
     ]
    }
   ],
   "source": [
    "base = \"LSTM_2_submit\"\n",
    "ext = \".csv\"\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    out_name = f\"{base}_{i}{ext}\"\n",
    "    if not os.path.exists(out_name):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "submission[[\"game_episode\", \"end_x\", \"end_y\"]].to_csv(out_name, index=False)\n",
    "print(\"saved:\", out_name)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
