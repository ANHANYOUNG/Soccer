# Transformer 5-Fold Ensemble Training Plan

## ì „ëµ ìš”ì•½
- **K = 32** (OOF ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
- **5-fold cross-validation** (GroupKFold by game_id)
- **3 seeds** for diversity: [42, 123, 456]
- **Total models: 3 seeds Ã— 5 folds = 15 models**

## ê³„ì‚°ëŸ‰ ë¶„ì„

### í•™ìŠµ ì‹œê°„ ì˜ˆìƒ
- 1ê°œ ëª¨ë¸ (150 epochs): ~30-40ë¶„ (GPU ê¸°ì¤€)
- **ì´ 15ê°œ ëª¨ë¸**: ~7.5-10ì‹œê°„

### GPU ë©”ëª¨ë¦¬
- ëª¨ë¸ í¬ê¸°: ~5MB per model (ë§¤ìš° ì‘ìŒ)
- Batch size 256: ~2-3GB VRAM
- **4 GPU ë³‘ë ¬ ê°€ëŠ¥**: 4ê°œ foldë¥¼ ë™ì‹œ í•™ìŠµ â†’ ì•½ 2-3ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶•

### ì¶”ë¡  ì‹œê°„
- 15ê°œ ëª¨ë¸ ì•™ìƒë¸” ì˜ˆì¸¡: ~5-10ë¶„
- ë©”ëª¨ë¦¬: 15 models Ã— 5MB = ~75MB (ë§¤ìš° ì ìŒ)

## í•™ìŠµ ë°©ë²•

### Option 1: ìˆœì°¨ í•™ìŠµ (ë‹¨ì¼ GPU)
```bash
cd /home/ahy0502/soccer/open_track1/Transformer

# train.pyì—ì„œ FOLD = Noneìœ¼ë¡œ ì„¤ì • (ì´ë¯¸ ì„¤ì •ë¨)
python train.py
```
â†’ ëª¨ë“  15ê°œ ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµ (~7-10ì‹œê°„)

### Option 2: ë³‘ë ¬ í•™ìŠµ (4 GPU) âœ… ì¶”ì²œ
ê° foldë¥¼ ë‹¤ë¥¸ GPUì—ì„œ ë™ì‹œì— í•™ìŠµ:

```bash
# í„°ë¯¸ë„ 1: Fold 0 (ëª¨ë“  seed)
CUDA_VISIBLE_DEVICES=0 python train.py --fold 0 &

# í„°ë¯¸ë„ 2: Fold 1 (ëª¨ë“  seed)
CUDA_VISIBLE_DEVICES=1 python train.py --fold 1 &

# í„°ë¯¸ë„ 3: Fold 2 (ëª¨ë“  seed)
CUDA_VISIBLE_DEVICES=2 python train.py --fold 2 &

# í„°ë¯¸ë„ 4: Fold 3,4 (ìˆœì°¨)
CUDA_VISIBLE_DEVICES=3 python train.py --fold 3
CUDA_VISIBLE_DEVICES=3 python train.py --fold 4
```

â†’ ~2-3ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶•!

**í•„ìš”í•œ ìˆ˜ì •**: `train.py`ì— `--fold` ì¸ì ì¶”ê°€ í•„ìš”

## ì¶”ë¡  ë°©ë²•

```bash
cd /home/ahy0502/soccer/open_track1/Transformer
python inference.py
```

ìë™ìœ¼ë¡œ `models/seed_*_fold_*` ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ëª¨ë¸(15ê°œ)ì„ ë¡œë“œí•˜ì—¬ ì•™ìƒë¸” ì˜ˆì¸¡:
1. ê° ëª¨ë¸ì´ ë…ë¦½ì ìœ¼ë¡œ ì˜ˆì¸¡
2. 15ê°œ ì˜ˆì¸¡ì˜ í‰ê· ì„ ìµœì¢… ì œì¶œ íŒŒì¼ë¡œ ìƒì„±
3. `Transformer_submit_X.csv` ì €ì¥

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
Transformer/
â”œâ”€â”€ train.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ oof_analysis.py
â””â”€â”€ models/
    â”œâ”€â”€ label_encoders.pkl (ê³µí†µ)
    â”œâ”€â”€ seed_42_fold_0/
    â”‚   â”œâ”€â”€ best_model.pt
    â”‚   â””â”€â”€ model_config.pkl
    â”œâ”€â”€ seed_42_fold_1/
    â”œâ”€â”€ seed_42_fold_2/
    â”œâ”€â”€ seed_42_fold_3/
    â”œâ”€â”€ seed_42_fold_4/
    â”œâ”€â”€ seed_123_fold_0/
    â”œâ”€â”€ ...
    â””â”€â”€ seed_456_fold_4/
```

## ì¶”ê°€ ê³ ë ¤ì‚¬í•­

### âœ… ì´ë¯¸ ì²˜ë¦¬ëœ ì‚¬í•­
1. **Data Leakage ë°©ì§€**: GroupKFoldë¡œ game_id ê¸°ì¤€ ë¶„ë¦¬
2. **Delta Prediction**: ë§ˆì§€ë§‰ start_x, start_y ê¸°ì¤€ ìƒëŒ€ì¢Œí‘œ ì˜ˆì¸¡
3. **Last Token Pooling**: ë§ˆì§€ë§‰ ìœ íš¨ í† í°ë§Œ ì‚¬ìš© (ì••ë„ì  ì„±ëŠ¥ í–¥ìƒ)
4. **Gaussian NLL Loss**: ë¶ˆí™•ì‹¤ì„± í•™ìŠµ
5. **K Truncation**: ìµœê·¼ 32ê°œ ì´ë²¤íŠ¸ì— ì§‘ì¤‘

### âš ï¸ ì¶”ê°€ ê²€í†  ê°€ëŠ¥ ì‚¬í•­
1. **Learning Rate Schedule**: ReduceLROnPlateau ì‚¬ìš© ì¤‘ (ì ì ˆí•¨)
2. **Early Stopping**: í˜„ì¬ ì—†ìŒ â†’ 150 epoch ê³ ì •
   - Valid distê°€ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ ì¶”ê°€ ê°€ëŠ¥
   - í•˜ì§€ë§Œ 150 epochë„ ì¶©ë¶„íˆ ë¹ ë¦„ (~30ë¶„)
3. **Test Time Augmentation (TTA)**: í˜„ì¬ ì—†ìŒ
   - ì¶”ë¡  ì‹œ ë…¸ì´ì¦ˆ ì¶”ê°€ ì˜ˆì¸¡ â†’ ë” robust
   - ì‹œê°„ 2ë°° ì¦ê°€ but ì„±ëŠ¥ ì†Œí­ í–¥ìƒ ê°€ëŠ¥
4. **Weighted Ensemble**: í˜„ì¬ ë‹¨ìˆœ í‰ê· 
   - Valid ì„±ëŠ¥ ê¸°ì¤€ ê°€ì¤‘ í‰ê·  ê°€ëŠ¥
   - í•˜ì§€ë§Œ ë‹¨ìˆœ í‰ê· ë„ ì¶©ë¶„íˆ íš¨ê³¼ì 

### ğŸ¯ í˜„ì¬ ì „ëµì˜ ì¥ì 
1. **Stability**: 5-foldë¡œ ì „ì²´ ë°ì´í„° í™œìš©
2. **Diversity**: 3 seedsë¡œ ì´ˆê¸°í™” ë‹¤ì–‘ì„±
3. **Efficiency**: K=32ë¡œ ê³„ì‚°ëŸ‰ ê°ì†Œ
4. **Robust**: 15 models ì•™ìƒë¸”ë¡œ ê³¼ì í•© ë°©ì§€

## ì˜ˆìƒ ì„±ëŠ¥
- **OOF validation**: ~13.7-13.9 (K=32 ê¸°ì¤€)
- **Leaderboard**: OOFì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ì•½ê°„ ê°œì„  (ì•™ìƒë¸” íš¨ê³¼)
- **ê°œì„  í­**: ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ~0.1-0.2 ê±°ë¦¬ ê°ì†Œ ì˜ˆìƒ

## ë‹¤ìŒ ë‹¨ê³„
1. âœ… `train.py` ìˆ˜ì • ì™„ë£Œ (5-fold ì§€ì›)
2. âœ… `inference.py` ìˆ˜ì • ì™„ë£Œ (15 models ì•™ìƒë¸”)
3. â¬œ `--fold` ì¸ì ì¶”ê°€ (ë³‘ë ¬ í•™ìŠµìš©) - ì„ íƒì‚¬í•­
4. â¬œ í•™ìŠµ ì‹¤í–‰
5. â¬œ ì¶”ë¡  ë° ì œì¶œ
